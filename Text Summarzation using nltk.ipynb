{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a424d115",
   "metadata": {},
   "source": [
    "# Text summerization using nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6017ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4add72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
    "from nltk.cluster.util import cosine_distance\n",
    "import numpy as np\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39ac3cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_text = \"\"\"\n",
    "Natural language processing (NLP) is a field of artificial intelligence that focuses on the interaction \n",
    "between computers and humans using natural language. The ultimate objective of NLP is to enable computers \n",
    "to understand, interpret, and generate human-like text. In recent years, NLP has seen tremendous advancements \n",
    "with the development of deep learning models and large-scale language models like GPT-3. These models have \n",
    "revolutionized various NLP tasks, including machine translation, sentiment analysis, and text summarization.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "524d56d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Tokenization\n",
    "sentences = sent_tokenize(sample_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4c3347d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\nNatural language processing (NLP) is a field of artificial intelligence that focuses on the interaction \\nbetween computers and humans using natural language.',\n",
       " 'The ultimate objective of NLP is to enable computers \\nto understand, interpret, and generate human-like text.',\n",
       " 'In recent years, NLP has seen tremendous advancements \\nwith the development of deep learning models and large-scale language models like GPT-3.',\n",
       " 'These models have \\nrevolutionized various NLP tasks, including machine translation, sentiment analysis, and text summarization.']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7998539",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [word_tokenize(sentence) for sentence in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "59ac86d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Natural',\n",
       "  'language',\n",
       "  'processing',\n",
       "  '(',\n",
       "  'NLP',\n",
       "  ')',\n",
       "  'is',\n",
       "  'a',\n",
       "  'field',\n",
       "  'of',\n",
       "  'artificial',\n",
       "  'intelligence',\n",
       "  'that',\n",
       "  'focuses',\n",
       "  'on',\n",
       "  'the',\n",
       "  'interaction',\n",
       "  'between',\n",
       "  'computers',\n",
       "  'and',\n",
       "  'humans',\n",
       "  'using',\n",
       "  'natural',\n",
       "  'language',\n",
       "  '.'],\n",
       " ['The',\n",
       "  'ultimate',\n",
       "  'objective',\n",
       "  'of',\n",
       "  'NLP',\n",
       "  'is',\n",
       "  'to',\n",
       "  'enable',\n",
       "  'computers',\n",
       "  'to',\n",
       "  'understand',\n",
       "  ',',\n",
       "  'interpret',\n",
       "  ',',\n",
       "  'and',\n",
       "  'generate',\n",
       "  'human-like',\n",
       "  'text',\n",
       "  '.'],\n",
       " ['In',\n",
       "  'recent',\n",
       "  'years',\n",
       "  ',',\n",
       "  'NLP',\n",
       "  'has',\n",
       "  'seen',\n",
       "  'tremendous',\n",
       "  'advancements',\n",
       "  'with',\n",
       "  'the',\n",
       "  'development',\n",
       "  'of',\n",
       "  'deep',\n",
       "  'learning',\n",
       "  'models',\n",
       "  'and',\n",
       "  'large-scale',\n",
       "  'language',\n",
       "  'models',\n",
       "  'like',\n",
       "  'GPT-3',\n",
       "  '.'],\n",
       " ['These',\n",
       "  'models',\n",
       "  'have',\n",
       "  'revolutionized',\n",
       "  'various',\n",
       "  'NLP',\n",
       "  'tasks',\n",
       "  ',',\n",
       "  'including',\n",
       "  'machine',\n",
       "  'translation',\n",
       "  ',',\n",
       "  'sentiment',\n",
       "  'analysis',\n",
       "  ',',\n",
       "  'and',\n",
       "  'text',\n",
       "  'summarization',\n",
       "  '.']]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "514f454a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a',\n",
       " 'about',\n",
       " 'above',\n",
       " 'after',\n",
       " 'again',\n",
       " 'against',\n",
       " 'ain',\n",
       " 'all',\n",
       " 'am',\n",
       " 'an',\n",
       " 'and',\n",
       " 'any',\n",
       " 'are',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'as',\n",
       " 'at',\n",
       " 'be',\n",
       " 'because',\n",
       " 'been',\n",
       " 'before',\n",
       " 'being',\n",
       " 'below',\n",
       " 'between',\n",
       " 'both',\n",
       " 'but',\n",
       " 'by',\n",
       " 'can',\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'd',\n",
       " 'did',\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'do',\n",
       " 'does',\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'doing',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'down',\n",
       " 'during',\n",
       " 'each',\n",
       " 'few',\n",
       " 'for',\n",
       " 'from',\n",
       " 'further',\n",
       " 'had',\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'has',\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'have',\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'having',\n",
       " 'he',\n",
       " 'her',\n",
       " 'here',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'him',\n",
       " 'himself',\n",
       " 'his',\n",
       " 'how',\n",
       " 'i',\n",
       " 'if',\n",
       " 'in',\n",
       " 'into',\n",
       " 'is',\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'just',\n",
       " 'll',\n",
       " 'm',\n",
       " 'ma',\n",
       " 'me',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'more',\n",
       " 'most',\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'my',\n",
       " 'myself',\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'now',\n",
       " 'o',\n",
       " 'of',\n",
       " 'off',\n",
       " 'on',\n",
       " 'once',\n",
       " 'only',\n",
       " 'or',\n",
       " 'other',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'out',\n",
       " 'over',\n",
       " 'own',\n",
       " 're',\n",
       " 's',\n",
       " 'same',\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'so',\n",
       " 'some',\n",
       " 'such',\n",
       " 't',\n",
       " 'than',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'the',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'them',\n",
       " 'themselves',\n",
       " 'then',\n",
       " 'there',\n",
       " 'these',\n",
       " 'they',\n",
       " 'this',\n",
       " 'those',\n",
       " 'through',\n",
       " 'to',\n",
       " 'too',\n",
       " 'under',\n",
       " 'until',\n",
       " 'up',\n",
       " 've',\n",
       " 'very',\n",
       " 'was',\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'we',\n",
       " 'were',\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'what',\n",
       " 'when',\n",
       " 'where',\n",
       " 'which',\n",
       " 'while',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'why',\n",
       " 'will',\n",
       " 'with',\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\",\n",
       " 'y',\n",
       " 'you',\n",
       " \"you'd\",\n",
       " \"you'll\",\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 2: Lowercasing and Removing Stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bce8f0b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_words = []\n",
    "for sentence_words in words:\n",
    "    filtered_words.append([word.lower() for word in sentence_words if word.isalnum() and word.lower() not in stop_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e71199f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['natural',\n",
       "  'language',\n",
       "  'processing',\n",
       "  'nlp',\n",
       "  'field',\n",
       "  'artificial',\n",
       "  'intelligence',\n",
       "  'focuses',\n",
       "  'interaction',\n",
       "  'computers',\n",
       "  'humans',\n",
       "  'using',\n",
       "  'natural',\n",
       "  'language'],\n",
       " ['ultimate',\n",
       "  'objective',\n",
       "  'nlp',\n",
       "  'enable',\n",
       "  'computers',\n",
       "  'understand',\n",
       "  'interpret',\n",
       "  'generate',\n",
       "  'text'],\n",
       " ['recent',\n",
       "  'years',\n",
       "  'nlp',\n",
       "  'seen',\n",
       "  'tremendous',\n",
       "  'advancements',\n",
       "  'development',\n",
       "  'deep',\n",
       "  'learning',\n",
       "  'models',\n",
       "  'language',\n",
       "  'models',\n",
       "  'like'],\n",
       " ['models',\n",
       "  'revolutionized',\n",
       "  'various',\n",
       "  'nlp',\n",
       "  'tasks',\n",
       "  'including',\n",
       "  'machine',\n",
       "  'translation',\n",
       "  'sentiment',\n",
       "  'analysis',\n",
       "  'text',\n",
       "  'summarization']]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8d32e22a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['natural',\n",
       " 'language',\n",
       " 'processing',\n",
       " 'nlp',\n",
       " 'field',\n",
       " 'artificial',\n",
       " 'intelligence',\n",
       " 'focuses',\n",
       " 'interaction',\n",
       " 'computers',\n",
       " 'humans',\n",
       " 'using',\n",
       " 'natural',\n",
       " 'language',\n",
       " 'ultimate',\n",
       " 'objective',\n",
       " 'nlp',\n",
       " 'enable',\n",
       " 'computers',\n",
       " 'understand',\n",
       " 'interpret',\n",
       " 'generate',\n",
       " 'text',\n",
       " 'recent',\n",
       " 'years',\n",
       " 'nlp',\n",
       " 'seen',\n",
       " 'tremendous',\n",
       " 'advancements',\n",
       " 'development',\n",
       " 'deep',\n",
       " 'learning',\n",
       " 'models',\n",
       " 'language',\n",
       " 'models',\n",
       " 'like',\n",
       " 'models',\n",
       " 'revolutionized',\n",
       " 'various',\n",
       " 'nlp',\n",
       " 'tasks',\n",
       " 'including',\n",
       " 'machine',\n",
       " 'translation',\n",
       " 'sentiment',\n",
       " 'analysis',\n",
       " 'text',\n",
       " 'summarization']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 3: Calculating Word Frequencies\n",
    "flat_list = [word for sublist in filtered_words for word in sublist]\n",
    "flat_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5a4b0c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_frequencies = FreqDist(flat_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aca914a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'nlp': 4, 'language': 3, 'models': 3, 'natural': 2, 'computers': 2, 'text': 2, 'processing': 1, 'field': 1, 'artificial': 1, 'intelligence': 1, ...})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b22f62a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_frequency = max(word_frequencies.values())\n",
    "max_frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f1848d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0689953c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in word_frequencies.keys():\n",
    "    word_frequencies[word] = word_frequencies[word]/max_frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d27c9a4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'nlp': 1.0, 'language': 0.75, 'models': 0.75, 'natural': 0.5, 'computers': 0.5, 'text': 0.5, 'processing': 0.25, 'field': 0.25, 'artificial': 0.25, 'intelligence': 0.25, ...})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "47c14a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Scoring Sentences based on Word Frequencies\n",
    "sentence_scores = {}\n",
    "for i, sentence in enumerate(filtered_words):\n",
    "    score = 0\n",
    "    for word in sentence:\n",
    "        score += word_frequencies[word]\n",
    "    sentence_scores[i] = score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d1a23b2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 6.0, 1: 3.5, 2: 5.5, 3: 4.5}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7a509b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting Top N Sentences for Summarization\n",
    "num_sentences = 2\n",
    "selected_sentences_indices = sorted(sentence_scores, key=sentence_scores.get, reverse=True)[:num_sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1b53097e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 2]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_sentences_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8fa7507f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating the Summary\n",
    "summary_sentences = [sent_tokenize(sample_text)[i] for i in selected_sentences_indices]\n",
    "summary = TreebankWordDetokenizer().detokenize(summary_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "75e1e3a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Text:\n",
      " \n",
      "Natural language processing (NLP) is a field of artificial intelligence that focuses on the interaction \n",
      "between computers and humans using natural language. The ultimate objective of NLP is to enable computers \n",
      "to understand, interpret, and generate human-like text. In recent years, NLP has seen tremendous advancements \n",
      "with the development of deep learning models and large-scale language models like GPT-3. These models have \n",
      "revolutionized various NLP tasks, including machine translation, sentiment analysis, and text summarization.\n",
      "\n",
      "\n",
      "Summary:\n",
      " Natural language processing (NLP) is a field of artificial intelligence that focuses on the interaction \n",
      "between computers and humans using natural language. In recent years, NLP has seen tremendous advancements \n",
      "with the development of deep learning models and large-scale language models like GPT-3.\n"
     ]
    }
   ],
   "source": [
    "# Displaying the Original Text and Summary\n",
    "print(\"Original Text:\\n\", sample_text)\n",
    "print(\"\\nSummary:\\n\", summary)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
